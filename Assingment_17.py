import streamlit as st

from langchain.document_loaders import SitemapLoader
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.vectorstores.faiss import FAISS
from langchain.embeddings import CacheBackedEmbeddings, OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.text_splitter import CharacterTextSplitter
from langchain.storage import LocalFileStore
from urllib.parse import urlparse

st.set_page_config(
    page_title = "SiteGPT"
    , page_icon = "ğŸ–¥ï¸"
)

st.title("SiteGPT")

with st.sidebar:
    url=None
    api_key = st.text_input( 'Input OpenAI API keys' , type='password')
    
    if api_key:
        st.success('Enter OpenAI API keys')
        url = st.text_input(
            label = "Write down a URL(only sitemap.xml)",
            placeholder  ="https://developers.cloudflare.com/sitemap-0.xml"
    
        )
        if url:
            st.success('Correct URL!!')
     
    st.markdown("""
    Github Repo : https://github.com/devowov/FullStack-GPT
    """)
    
def parse_page(soup):
    return (
        str(soup.find("main").get_text())
        .replace("\n", " ")
        .replace("\xa0", " ")
        .replace("Edit page   Cloudflare DashboardDiscordCommunityLearning CenterSupport Portal  Cookie Settings", "")
    )

@st.cache_resource(show_spinner="Scraping & Embedding...")
def load_website(url):
    loader = SitemapLoader(
        url
        , filter_urls=[
            r"^(.*\/workers-ai\/).*",
            r"^(.*\/vectorize\/).*",
            r"^(.*\/ai-gateway\/).*",
        ]
        , parsing_function=parse_page
    )
    
    splitter = CharacterTextSplitter.from_tiktoken_encoder(
        chunk_size = 1000
        , chunk_overlap = 200
    )
    
    docs = loader.load_and_split(text_splitter = splitter)
    
    embeddings = OpenAIEmbeddings(api_key=api_key)
    vector_store = FAISS.from_documents(docs, embeddings)
    return vector_store.as_retriever()

def get_answers(input):
    docs = input['docs']
    question = input['question']        
    answers_chain = answers_prompt | llm
    return {
        'question': question,
        'answers': [
            {
                'answer': answers_chain.invoke(
                    {'question': question, 'context': doc.page_content}
                ).content,
                'source': doc.metadata['source'],
                "date": doc.metadata['lastmod']
            } for doc in docs
        ]
    }

def choose_answer(input):
    question = input['question']
    answers = input['answers']
    
    choose_chain = choose_prompt | llm
    condensed = '\n\n'.join(f"{answer['answer']}\n{answer['source']}" for answer in answers)
    
    return choose_chain.invoke(
        {
            'context': condensed,
            'question': question
        } 
    )

def send_message(role, message, save=True):
    with st.chat_message(role):
        st.write(message)
    if save:
        save_message(role, message)

def paint_history():
    for message in st.session_state['messages']:
        send_message(message['role'], message['message'], save=False)

def save_message(role, message):
    st.session_state['messages'].append(
            {
                'role': role,             
                'message': message,
            }
        )        

answers_prompt = ChatPromptTemplate.from_messages([
    (
        'system',
        '''
            ë‹¤ìŒê³¼ ê°™ì´ contextë¥¼ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€ë‹µí•´ì•¼í•©ë‹ˆë‹¤.
            ëª¨ë¥´ê² ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ëŒ€ë‹µí•˜ë©´ ë©ë‹ˆë‹¤. ê³¼ì¥ì—†ì´ ëŒ€ë‹µí•˜ì„¸ìš”.
            
            ëŒ€ë‹µì— ëŒ€í•œ ì ìˆ˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
            ì ìˆ˜ëŠ” 0ì ì—ì„œ 5ì ê¹Œì§€ ë¶€ì—¬í•©ë‹ˆë‹¤.
            ì§ˆë¬¸ì— ëŒ€í•´ ì ì ˆí•œ ë‹µë³€ì¼ ìˆ˜ë¡ ë†’ì€ ì ìˆ˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
            ì ì ˆí•˜ì§€ ì•Šì„ ìˆ˜ë¡ ì ìˆ˜ëŠ” ë‚®ì•„ì§‘ë‹ˆë‹¤.

            Context: {context}

            ì˜ˆì‹œ:
                question: ë‹¬ì€ ì–¼ë§ˆë‚˜ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆë‚˜ìš”?
                answer: ë‹¬ì€ 384,400 km ë–¨ì–´ì ¸ìˆìŠµë‹ˆë‹¤.
                score: 5

                question: íƒœì–‘ì€ ì–¼ë§ˆë‚˜ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆë‚˜ìš”?
                answer: ëª¨ë¦…ë‹ˆë‹¤.
                score: 0

                ì´ì œ ë‹¹ì‹ ì˜ ì°¨ë¡€ì…ë‹ˆë‹¤!

                question: {question}
        '''
    ),
    ('human', '{question}')
])    

choose_prompt = ChatPromptTemplate.from_messages([
    (
        'system',
        """
            ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì€ ì •í•´ì§„ ì˜ˆì‹œë¡œë§Œ ë‹µë³€í•œë‹¤.
            ê°€ì¥ ì ìˆ˜ê°€ ë†’ì€ ë‹µë³€ì„ ìµœìš°ì„ ìœ¼ë¡œ ì„ íƒí•˜ì—¬ ë‹µë³€í•œë‹¤.
            ì¶œì²˜ì— ëŒ€í•´ ê¼­ í‘œê¸°í•œë‹¤.

            context: {context}
        """
    ),
    ('human', '{question}')
])


if not url:
    st.markdown(
        """
       Ask questions about the content of Cloudflare's documentation.
            
        The chatbot gives you answers about AI Gateway, Cloudflare Vectorize, and Workers AI.
        
        Enter your OpenAI API Key to ask questions.
        """
    )    
    st.session_state['messages'] = []    

elif not ".xml" in url:
    st.error('please write down a Sitemap URL')
elif url:
    retriever = load_website(url)

    send_message('ai', 'Ask anything', save=False)

    paint_history()

    llm = ChatOpenAI(
    # model_name="gpt-3.5-turbo"
    # , 
    temperature=0.1
    , streaming=True
    )

    question = st.chat_input()
    if question:
        send_message('human', question, save=True)
        
        chain = (
            {
                'docs': retriever,
                'question': RunnablePassthrough()
            }
            | RunnableLambda(get_answers)
            | RunnableLambda(choose_answer)
        )        
        
        result = chain.invoke(question)
        
        send_message('ai', result.content, save=True)
